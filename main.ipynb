{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())  # True = GPU exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIG ==========\n",
    "DATA_DIR = 'tammathon-task-1\\\\train\\\\train\\\\' #change here to your folder\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "N = 999999 # how many folders to use (for testing purposes you can set N = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 71.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ========== STEP 1: LOAD & SPLIT DATA ==========\n",
    "def load_image_paths(data_dir):\n",
    "    dirs = os.listdir(data_dir)\n",
    "    label_names = dirs[:N]\n",
    "    print(len(label_names))\n",
    "    \n",
    "    label_to_idx = {label: idx for idx, label in enumerate(label_names)}\n",
    "    idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "\n",
    "    for i, label_name in enumerate(label_names):\n",
    "        label_path = os.path.join(data_dir, label_name)\n",
    "        image_paths = [os.path.join(label_path, f) for f in os.listdir(label_path) if f.endswith('.png')]\n",
    "        \n",
    "        if len(image_paths) >= 3:\n",
    "            train_data.extend((img, label_to_idx[label_name]) for img in image_paths[1:])\n",
    "            val_data.append((image_paths[0], label_to_idx[label_name]))\n",
    "        else:\n",
    "            train_data.extend((img, label_to_idx[label_name]) for img in image_paths[:])\n",
    "        \n",
    "        if not i % 10000:\n",
    "            print(i)\n",
    "\n",
    "    return train_data, val_data, label_to_idx, idx_to_label\n",
    "\n",
    "\n",
    "train_data, val_data, label_to_idx, idx_to_label = load_image_paths(DATA_DIR)\n",
    "num_classes = len(label_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== STEP 2: DEFINE DATASET ==========\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class CatDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "train_dataset = CatDataset(train_data, transform=transform)\n",
    "val_dataset = CatDataset(val_data, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\z20250128\\myvenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Projects\\z20250128\\myvenv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# ========== STEP 3: MODEL SETUP ==========\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.3615\n",
      "Epoch 2/10, Loss: 1.1363\n",
      "Epoch 3/10, Loss: 1.1422\n",
      "Epoch 4/10, Loss: 0.5658\n",
      "Epoch 5/10, Loss: 0.5271\n",
      "Epoch 6/10, Loss: 0.4517\n",
      "Epoch 7/10, Loss: 0.2322\n",
      "Epoch 8/10, Loss: 0.1679\n",
      "Epoch 9/10, Loss: 0.3401\n",
      "Epoch 10/10, Loss: 0.3134\n"
     ]
    }
   ],
   "source": [
    "# ========== STEP 4: TRAINING LOOP ==========\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    result_vars = {'model': model,\n",
    "                   'running_loss': running_loss,\n",
    "                   'optimizer': optimizer,\n",
    "                   'outputs': outputs,\n",
    "                   'loss': loss}\n",
    "        \n",
    "    with open(f'result_vars_epoch{epoch+1}.pkl', 'wb') as f:\n",
    "        pickle.dump(result_vars, f)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {running_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========== STEP 5: VALIDATION & PREDICTION ==========\n",
    "\n",
    "model.eval()\n",
    "top3_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, true_label in val_loader:\n",
    "        image = image.to(DEVICE)\n",
    "        outputs = model(image)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        top3 = torch.topk(probs, 3)\n",
    "        top3_idxs = top3.indices.cpu().numpy()[0]\n",
    "        top3_labels = [idx_to_label[i] for i in top3_idxs]\n",
    "        top3_predictions.append(top3_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: tammathon-task-1\\train\\train\\000000\\00.png\n",
      "True Label: 000000\n",
      "Top 3 Predicted Labels: ['000000', '000008', '000009']\n",
      "----------------------------------------\n",
      "Image: tammathon-task-1\\train\\train\\000001\\00.png\n",
      "True Label: 000001\n",
      "Top 3 Predicted Labels: ['000002', '000001', '000009']\n",
      "----------------------------------------\n",
      "Image: tammathon-task-1\\train\\train\\000002\\00.png\n",
      "True Label: 000002\n",
      "Top 3 Predicted Labels: ['000002', '000006', '000005']\n",
      "----------------------------------------\n",
      "Image: tammathon-task-1\\train\\train\\000003\\00.png\n",
      "True Label: 000003\n",
      "Top 3 Predicted Labels: ['000003', '000005', '000002']\n",
      "----------------------------------------\n",
      "Image: tammathon-task-1\\train\\train\\000004\\00.png\n",
      "True Label: 000004\n",
      "Top 3 Predicted Labels: ['000004', '000000', '000002']\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ========== STEP 6: OUTPUT RESULTS ==========\n",
    "\n",
    "for i, (img_path, true_label) in enumerate(val_data[:5]):\n",
    "    true_label_str = idx_to_label[true_label]\n",
    "    print(f\"Image: {img_path}\")\n",
    "    print(f\"True Label: {true_label_str}\")\n",
    "    print(f\"Top 3 Predicted Labels: {top3_predictions[i]}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Calculate top-3 accuracy\n",
    "correct = 0\n",
    "total = len(val_data)\n",
    "\n",
    "for i, (_, true_label) in enumerate(val_data):\n",
    "    predicted_labels = top3_predictions[i]\n",
    "    true_label_str = idx_to_label[true_label]\n",
    "    if true_label_str in predicted_labels:\n",
    "        correct += 1\n",
    "\n",
    "top3_accuracy = correct / total\n",
    "print(f\"Top-3 Accuracy: {top3_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
